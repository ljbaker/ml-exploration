{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae75be8",
   "metadata": {},
   "source": [
    "# Building a Random Forest Classifier from Scratch\n",
    "\n",
    "Data science lunch and learn -- 04/01/2022\n",
    "\n",
    "It's surprisingly easy, and useful as a tutorial. Let's go!\n",
    "\n",
    "## The Algorithm\n",
    "\n",
    "A random forest decision tree classifier is a probabalistic extension of a vanilla decision tree. Decision trees use logical rules to parse features into finer and finer buckets, making decisions on the final nodes. This could look like a classifier for cats vs dogs with the following rules:\n",
    "\n",
    "START --> POINTY EARS? --YES--> UNDER 20 LBS? --YES--> ...\n",
    "                       \\                      \\--NO--> ...\n",
    "                        \\-NO--> UNDER 20 LBS? --YES--> ...\n",
    "                         \\                    \\--NO--> ...\n",
    "                         \n",
    "                         \n",
    "At the end of all our questions, we have a bin with a certain probability of being a cat or a dog. There are dogs with pointy ears (Doberman Pinschers come to mind), and their are cats bigger than 20 lbs (Maine Coons, or my mom's exceptionally fat shorthair), but odds are pretty good that an animal under 20 lbs with pointy ears is going to be a cat. We can add more rules for more and more specific binning (e.g., \"wet nose vs dry nose?\", \"tail length > 30% body length?\"), but you get the point.\n",
    "\n",
    "Random forest classifiers differ from decision trees in a few simple ways. First, the rules are procedurally generated. This is also common in algorithmic decision trees, but it's worth mentioning in opposition to our toy example above. Given a sample of data with $n$ features, the algorithm will identify the feature that best distinguishes the classes and split the node, moving through multiple features or combinations of features to a given stop rule. \n",
    "\n",
    "Second, the algorithm is actually an *ensemble* of multiple decision trees. This derives from the wisdom of crowds phenomenon, which finds that a collection of weakly correlated learners will outperform a single strong predictor over time. Majority vote wins. So, if 600/1000 component trees say it's a cat, the algorithm will vote \"cat\".\n",
    "\n",
    "Third, each component decision tree is made from a sample of the data, called a bag (aka bootstrap aggregation). \n",
    "\n",
    "Fourth, the algorithm enforces feature randomization. Each tree is limited by the set of features on which they are allowed to split a node.\n",
    "\n",
    "These four innovations (probabalistic splitting, ensemble voting, bagged sampling, and feature randomization) lead to a surprisingly lightweight and robust classifier.\n",
    "\n",
    "\n",
    "## Building a Random Forest\n",
    "\n",
    "Taking that description, the basic outline of a random forest algorithm is\n",
    "\n",
    "```\n",
    "For each of N trees:\n",
    "    - create a new bag (bootstrapped sample with replacementy) from the training set\n",
    "    - use this bag to train a decision tree\n",
    "    - at each node of the decision tree, randomly select *m* features, and select the optimal feature to divide the node (we'll use Shannon entropy but you can also use Gini impurity)\n",
    "    - repeat to a stop rule OR all nodes complete\n",
    "```\n",
    "\n",
    "\n",
    "# Data\n",
    "\n",
    "Let's use the relatively straightforward UCI Car Evaluation dataset. This uses six features to determine whether a car is a acceptable or unacceptable quality. This is a pretty standard toy dataset, although I can't really speak to it's quality. Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3c70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c73eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1bffb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  label\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=requests.get(url).content\n",
    "columns = ['buying','maint','doors','persons','lug_boot','safety', 'label']\n",
    "df=pd.read_csv(io.StringIO(s.decode('utf-8')), header=None)\n",
    "df.columns = columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1635ef",
   "metadata": {},
   "source": [
    "### Formatting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3424b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buying': array(['vhigh', 'high', 'med', 'low'], dtype=object),\n",
       " 'maint': array(['vhigh', 'high', 'med', 'low'], dtype=object),\n",
       " 'doors': array(['2', '3', '4', '5more'], dtype=object),\n",
       " 'persons': array(['2', '4', 'more'], dtype=object),\n",
       " 'lug_boot': array(['small', 'med', 'big'], dtype=object),\n",
       " 'safety': array(['low', 'med', 'high'], dtype=object),\n",
       " 'label': array(['unacc', 'acc', 'vgood', 'good'], dtype=object)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdict = {c:df[c].unique() for c in columns}\n",
    "\n",
    "cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83434b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdict = {'vhigh':4, 'high':3, 'med':2, 'low':1}\n",
    "df = df.replace({\"buying\": bdict})\n",
    "# using the same dictionary\n",
    "df = df.replace({\"maint\": bdict})\n",
    "\n",
    "bdict = {'2':2, '3':3, '4':4, '5more':5}\n",
    "df = df.replace({\"doors\": bdict})\n",
    "\n",
    "bdict = {'2':2, '4':4, 'more':5}\n",
    "df = df.replace({\"persons\": bdict})\n",
    "\n",
    "bdict = {'small':1, 'med':2, 'big':3}\n",
    "df = df.replace({\"lug_boot\": bdict})\n",
    "\n",
    "bdict = {'low':1, 'med':2, 'high':3}\n",
    "df = df.replace({\"safety\": bdict})\n",
    "\n",
    "bdict = {'unacc':0, 'acc':1, 'good':2, 'vgood':3}\n",
    "df = df.replace({\"label\": bdict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10353b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  label\n",
       "0       4      4      2        2         1       1      0\n",
       "1       4      4      2        2         1       2      0\n",
       "2       4      4      2        2         1       3      0\n",
       "3       4      4      2        2         2       1      0\n",
       "4       4      4      2        2         2       2      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1538d003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      int64\n",
       "maint       int64\n",
       "doors       int64\n",
       "persons     int64\n",
       "lug_boot    int64\n",
       "safety      int64\n",
       "label       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306cfcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiclass problem\n",
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e9360",
   "metadata": {},
   "source": [
    "# Getting Started: The Basic Decision Tree\n",
    "\n",
    "A random forest model is an expansion on a basic decision tree. The classic decision tree takes the following steps, which I've ordered in the class `dtree`:\n",
    "\n",
    "1. read_data. We need to get the data and store it in the class. Since this is a fully supervised problem, we need complete data with features as columns and individual measures (here, cars) for every row. We also need labeled classes for each training sample.\n",
    "\n",
    "2. make_tree. Loop through the data with the following steps at each loop:\n",
    "\n",
    "2.1. calculate available features and classes to make a decision from.\n",
    "2.2. calculate the default class (the most likely one on a blind guess) and the default entropy of the system. We'll use these to decide wherther a decision is better than chance.\n",
    "2.3. find the best feature to make a decision. We do this by calculating the entropy (or Gini impurity) of make a decision on each of the available features. The feature that yields the most information is the winner, and is use to split the data.\n",
    "2.4. add the decision point to the tree.\n",
    "2.5. repeat steps 2.1-2.4 until no features remain.\n",
    "\n",
    "3. Print the tree for review (this is kind of annoying so I've hacked something that works. There are much better alternatives for visualizing graphs out there in the world).\n",
    "\n",
    "4. Predict holdout data for validaiton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dcba2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "class dtree:\n",
    "    \"\"\" A basic Decision Tree\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        \n",
    "\n",
    "    def read_data(self,filename):\n",
    "        data = pd.read_csv('car_evaluation.csv')\n",
    "\n",
    "        self.featureNames = data.columns[:-1].tolist()\n",
    "        self.classes = data.label\n",
    "        data = data[self.featureNames]\n",
    "        \n",
    "        return data, self.classes, self.featureNames\n",
    "    \n",
    "\n",
    "    def graph_depth(tree_dict):\n",
    "        \"\"\"\n",
    "        Utility function for identifying tree (graph) depth\n",
    "        \"\"\"\n",
    "        if isinstance(tree_dict, dict):\n",
    "\n",
    "            return 1 + (max(map(dict_depth, tree_dict.values()))\n",
    "                                        if tree_dict else 0)\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    def get_default_entropy(self, classes, newClasses, nData, metric='entropy'):\n",
    "        \"\"\"\n",
    "        calculate baseline entropy and default class for a sample\n",
    "        \"\"\"\n",
    "        information = 0\n",
    "        frequency = pd.Series(newClasses).value_counts()\n",
    "\n",
    "        for freq in frequency:\n",
    "            if metric=='gini':\n",
    "                information += self.calc_gini(freq/nData)\n",
    "            else:\n",
    "                information += self.calc_entropy(freq/nData)\n",
    "\n",
    "        default = frequency.idxmax()\n",
    "\n",
    "        return information, frequency, default\n",
    "    \n",
    "    \n",
    "    def count_classes(self, classes):\n",
    "        return np.unique(classes)\n",
    "    \n",
    "\n",
    "    def select_feature(self, information, data, featureNames, classes, forest = 0, metric='entropy'):\n",
    "        \"\"\"\n",
    "        use entropy or gini impurity coefficient to identify best\n",
    "        feature for decision to be made\n",
    "        \n",
    "        Parameters\n",
    "        information\n",
    "        data : list(list(int))\n",
    "            data structure of feature variables\n",
    "        featureNames : list(str)\n",
    "            list of features to decide between\n",
    "        classes : list(int)\n",
    "            labels for data\n",
    "        forest : int\n",
    "            number of features to select at random for decision\n",
    "            used when implementing decision tree as a random forest\n",
    "        metric : str\n",
    "            if 'entropy', uses Shannon entropy to decide most informative feature\n",
    "            to make decision on\n",
    "            if 'gini', uses Gini impurity\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        gain : float\n",
    "            information gain\n",
    "        bestFeature : str\n",
    "            best feature to split decision tree\n",
    "        \"\"\"\n",
    "        gain = np.zeros(len(featureNames))\n",
    "#         featureSet = range(nFeatures)\n",
    "        \n",
    "        if forest != 0:\n",
    "            np.random.shuffle(featureNames)\n",
    "            featureNames = featureNames[0:forest]\n",
    "        for f, feature in enumerate(featureNames):\n",
    "            g = self.calc_info_gain(data,classes,feature)\n",
    "            gain[f] = information - g\n",
    "\n",
    "        bestFeature = featureNames[np.argmax(gain)]\n",
    "        \n",
    "        return gain, bestFeature\n",
    "    \n",
    "    \n",
    "    def make_tree(self,data,classes,featureNames,maxlevel=-1,level=0,forest=0):\n",
    "        \"\"\" \n",
    "        \n",
    "        Make a decision tree!\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            n x m array of feature values for the dataset, without labels\n",
    "            includes featureNames as columns\n",
    "        classes : pd.Series\n",
    "            n x 1 array of known target values for the dataset\n",
    "        featureNames : list\n",
    "            m-length list of feature names; subset of columns of data df\n",
    "        maxlevel : int\n",
    "            maximum depth of the tree\n",
    "        level : int\n",
    "            current level of the tree\n",
    "            function will be used recursively to elevate level of the tree\n",
    "        forest : int\n",
    "            number of features to randomly exclude at each node\n",
    "            if forest = 0, all features are used at every node\n",
    "            \n",
    "            e.g. forest = 2 and n_features=10, then 2 features\n",
    "            will be randomly selected and 8 features excluded\n",
    "            at every node.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tree : dict\n",
    "            nested dictionary of graph structure\n",
    "        \"\"\"\n",
    "\n",
    "        nData = data.shape[0]\n",
    "        nFeatures = data.shape[1]\n",
    "\n",
    "        try: \n",
    "            self.featureNames\n",
    "        except:\n",
    "            self.featureNames = featureNames\n",
    "\n",
    "        # List the possible classes\n",
    "        newClasses = self.count_classes(classes)\n",
    "\n",
    "        # Compute the default class (and total entropy)\n",
    "        information, frequency, default = self.get_default_entropy(classes, newClasses, nData)\n",
    "        \n",
    "        # find the best feature to branch\n",
    "\n",
    "        if nData==0 or nFeatures == 0 or (maxlevel>=0 and level>maxlevel):\n",
    "            # Have reached an empty branch\n",
    "            return default\n",
    "        elif len(np.unique(classes)) == 1:\n",
    "            # Only 1 class remains\n",
    "            return np.unique(classes)[0]\n",
    "        else:            \n",
    "            gain, bestFeature = self.select_feature(information, \n",
    "                                                    data, \n",
    "                                                    featureNames,\n",
    "                                                    classes)\n",
    "            \n",
    "            tree = {bestFeature:{}}\n",
    "            \n",
    "            # recurse until complete\n",
    "            # List the values that bestFeature can take\n",
    "            values = []\n",
    "            for idx, datapoint in data.iterrows():\n",
    "                if datapoint[bestFeature] not in values:\n",
    "                    values.append(datapoint[bestFeature])\n",
    "\n",
    "            for value in values:\n",
    "\n",
    "                newData = data[data[bestFeature] == value]\n",
    "                newClasses = classes[data[bestFeature] == value]\n",
    "                newNames = [f for f in featureNames if f != bestFeature]\n",
    "                \n",
    "                # Now recurse to the next level\n",
    "                subtree = self.make_tree(data = newData,\n",
    "                                         classes=newClasses,\n",
    "                                         featureNames=newNames,\n",
    "                                         maxlevel=maxlevel,\n",
    "                                         level=level+1,\n",
    "                                         forest=forest)\n",
    "\n",
    "                # And on returning, add the subtree on to the tree\n",
    "                tree[bestFeature][value] = subtree\n",
    "\n",
    "            return tree        \n",
    "            \n",
    "\n",
    "    def printTree(self,tree,name=''):\n",
    "        \"\"\"\n",
    "        Admittedly inelegant way to plot the tree\n",
    "        \"\"\"\n",
    "        if type(tree) == dict:\n",
    "            print(name, list(tree.keys())[0])\n",
    "            for item in list(tree.values())[0].keys():\n",
    "                print(name, item)\n",
    "                self.printTree(list(tree.values())[0][item], name + \"\\t\")\n",
    "        else:\n",
    "            print(name, \"\\t->\\t\", tree)\n",
    "    \n",
    "\n",
    "    def calc_entropy(self, p):\n",
    "        out = -p * np.log2(p)\n",
    "        return np.nan_to_num(out).sum()\n",
    "    \n",
    "        \n",
    "    def calc_gini(self, p):\n",
    "        p = np.array(p)\n",
    "        return 1-sum((p**2))\n",
    "    \n",
    "\n",
    "    def calc_info_gain(self,data,classes,feature, metric='entropy'):\n",
    "        \"\"\"\n",
    "        Calculates the information gain based on both entropy and the Gini impurity\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "        \n",
    "        classes : pd.Series\n",
    "        \n",
    "        feature : str\n",
    "            feature name in data.columns\n",
    "        \n",
    "        metric : str\n",
    "            if 'entropy', uses Shannon entropy to decide most informative feature\n",
    "            to make decision on\n",
    "            if 'gini', uses Gini impurity\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        gain : float\n",
    "            information gain for a decision on a given feature\n",
    "        \"\"\"\n",
    "        gain = 0\n",
    "        nData = len(data)\n",
    "\n",
    "        values = data[feature].unique()\n",
    "        featureCounts = data[feature].value_counts()\n",
    "        information = np.zeros(len(featureCounts))\n",
    "\n",
    "        # Find where those values appear in data[feature] and the corresponding class\n",
    "        for v, value in enumerate(values):\n",
    "            newClasses = classes.loc[data[feature]==value]\n",
    "            classValues = newClasses.unique()\n",
    "            classCounts = newClasses.value_counts()\n",
    "\n",
    "            if metric == 'gini':\n",
    "                information[v] = self.calc_gini(classCounts / np.sum(classCounts))\n",
    "            else:\n",
    "                information[v] = self.calc_entropy(classCounts / np.sum(classCounts))\n",
    "            \n",
    "            gain += featureCounts[value]/nData * information[v]\n",
    "            \n",
    "        return gain\n",
    "\n",
    "    \n",
    "    def graph_depth(self, tree_dict):\n",
    "        \"\"\"\n",
    "        Utility function for identifying tree (graph) depth\n",
    "        \"\"\"\n",
    "        if isinstance(tree_dict, dict):\n",
    "\n",
    "            return 1 + (max(map(self.graph_depth, tree_dict.values()))\n",
    "                                        if tree_dict else 0)\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    def predict(self, tree, datapoint, verbose=False):\n",
    "        \"\"\"\n",
    "        predict a single user's class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : dict\n",
    "            graph structure of the decision tree\n",
    "        datapoint : pd.Series\n",
    "            row of data from a dataframe containing an individual user's data\n",
    "            with feature names on the index\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_hat : pd.Series\n",
    "            pandas Series of predictions\n",
    "            may contain Nonetype values if no graph exists for a user's data\n",
    "        \"\"\"\n",
    "        for key, val in datapoint.iteritems():\n",
    "            if key in tree.keys():\n",
    "                if verbose:\n",
    "                    print(f'index: {datapoint.name} {key}: {val}')\n",
    "                try:\n",
    "                    tree = tree[key][val]\n",
    "                except:\n",
    "                    tree = None\n",
    "                if isinstance(tree, dict):\n",
    "                    return self.predict(tree, datapoint, verbose)\n",
    "                else:\n",
    "                    return tree\n",
    "\n",
    "    def predictAll(self, tree, data):    \n",
    "        \"\"\"\n",
    "        bulk predict on a pandas dataframe of values\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : dict\n",
    "            graph structure of the decision tree\n",
    "        data : pd.DataFrame\n",
    "            dataframe with users on the index and feature as labeled colums\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_hat : pd.Series\n",
    "            pandas Series of predictions\n",
    "            may contain Nonetype values if no graph exists for a user's data\n",
    "        \"\"\"\n",
    "        f = partial(self.predict, tree)\n",
    "        return data.apply(f, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f83cdde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dtree()\n",
    "\n",
    "data, classes, featureNames = dt.read_data('car_evaluation.csv')\n",
    "\n",
    "shuff = np.arange(len(data))\n",
    "np.random.shuffle(shuff)\n",
    "train_idx = shuff[:-200]\n",
    "test_idx = shuff[-200:]\n",
    "\n",
    "train = data.loc[train_idx]\n",
    "test =  data.loc[test_idx]\n",
    "\n",
    "train_classes = classes[train_idx]\n",
    "test_classes = classes[test_idx]\n",
    "\n",
    "dt.classes = train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aada460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety\n",
       "0       4      4      2        2         1       1\n",
       "1       4      4      2        2         1       2\n",
       "2       4      4      2        2         1       3\n",
       "3       4      4      2        2         2       1\n",
       "4       4      4      2        2         2       2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf8f8c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = dt.make_tree(train, train_classes, featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e7c6b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check depth of graph\n",
    "dt.graph_depth(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01a0bb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " safety\n",
      " 2\n",
      "\t persons\n",
      "\t 4\n",
      "\t\t buying\n",
      "\t\t 2\n",
      "\t\t\t maint\n",
      "\t\t\t 4\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t 2\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t\t 3\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t 4\n",
      "\t\t\t maint\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 3\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 4\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 2\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t 1\n",
      "\t\t\t maint\n",
      "\t\t\t 2\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t 3\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t\t 4\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t 3\n",
      "\t\t\t lug_boot\n",
      "\t\t\t 2\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t maint\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t maint\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 1\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 3\n",
      "\t\t\t\t maint\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t 5\n",
      "\t\t buying\n",
      "\t\t 4\n",
      "\t\t\t maint\n",
      "\t\t\t 2\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t 4\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 3\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t 2\n",
      "\t\t\t maint\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 3\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t 2\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t lug_boot\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 4\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t 3\n",
      "\t\t\t lug_boot\n",
      "\t\t\t 1\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 3\n",
      "\t\t\t\t maint\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t 2\n",
      "\t\t\t\t maint\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t 1\n",
      "\t\t\t maint\n",
      "\t\t\t 3\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t lug_boot\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 4\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 0\n",
      "\t\t\t 2\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t 2\n",
      "\t\t \t->\t 0\n",
      " 1\n",
      "\t \t->\t 0\n",
      " 3\n",
      "\t persons\n",
      "\t 5\n",
      "\t\t buying\n",
      "\t\t 1\n",
      "\t\t\t maint\n",
      "\t\t\t 4\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t lug_boot\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 2\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t 3\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t 2\n",
      "\t\t\t maint\n",
      "\t\t\t 3\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t lug_boot\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t 2\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t 4\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t lug_boot\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t 4\n",
      "\t\t\t maint\n",
      "\t\t\t 4\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 2\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t lug_boot\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 3\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 1\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t 3\n",
      "\t\t\t maint\n",
      "\t\t\t 3\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 2\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t lug_boot\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 1\n",
      "\t\t\t\t doors\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t lug_boot\n",
      "\t\t\t\t\t 1\n",
      "\t\t\t\t\t\t \t->\t 0\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 5\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 4\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 4\n",
      "\t\t\t\t \t->\t 0\n",
      "\t 2\n",
      "\t\t \t->\t 0\n",
      "\t 4\n",
      "\t\t buying\n",
      "\t\t 4\n",
      "\t\t\t maint\n",
      "\t\t\t 4\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 1\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t\t 3\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 2\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t 3\n",
      "\t\t\t maint\n",
      "\t\t\t 4\n",
      "\t\t\t\t \t->\t 0\n",
      "\t\t\t 2\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t\t 1\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t\t 3\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t 1\n",
      "\t\t\t maint\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t 3\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t 2\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 3\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t 4\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t 2\n",
      "\t\t\t maint\n",
      "\t\t\t 3\n",
      "\t\t\t\t \t->\t 1\n",
      "\t\t\t 1\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t doors\n",
      "\t\t\t\t\t 4\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 5\n",
      "\t\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t\t 2\n",
      "\t\t\t\t\t\t \t->\t 2\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t 2\n",
      "\t\t\t\t lug_boot\n",
      "\t\t\t\t 3\n",
      "\t\t\t\t\t \t->\t 3\n",
      "\t\t\t\t 1\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t\t 2\n",
      "\t\t\t\t\t \t->\t 1\n",
      "\t\t\t 4\n",
      "\t\t\t\t \t->\t 1\n"
     ]
    }
   ],
   "source": [
    "# plot graph structure\n",
    "dt.printTree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c667a",
   "metadata": {},
   "source": [
    "### Verifying training performance\n",
    "\n",
    "Decision trees are deterministic. We should not see any null values in their prediction. Classification of the training set should be 100% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4094077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = dt.predictAll(tree, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13c96ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f9decc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3af65af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1076\n",
      "           1       1.00      1.00      1.00       344\n",
      "           2       1.00      1.00      1.00        54\n",
      "           3       1.00      1.00      1.00        54\n",
      "\n",
      "    accuracy                           1.00      1528\n",
      "   macro avg       1.00      1.00      1.00      1528\n",
      "weighted avg       1.00      1.00      1.00      1528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perfect reproduction of training data\n",
    "print(classification_report(train_classes, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b208d04a",
   "metadata": {},
   "source": [
    "### Testing set performance\n",
    "\n",
    "Notably, decision trees cannot classify a combination of features they've never seen before. As a result, we're going to have some null values for weird edge causes (a 5-door care with 0 safety rating and a weird lug boot? Probably only one of those). \n",
    "\n",
    "There are two ways to hand that. One is to just admit that you cannot predict edge cases, and return null. This tends to make our data look better than it really is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8f50878",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = dt.predictAll(tree, test)\n",
    "y_hat.name = 'predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73295cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([y_hat, test_classes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28fda5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nonull = results.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dc1dd85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.956\n",
      "chance is 0.731\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy is {accuracy_score(results_nonull.label, results_nonull.predictions):.3f}')\n",
    "print(f'chance is {sum(np.array(results_nonull.label) == results_nonull.label.value_counts().idxmax())/len(results_nonull.label):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1496f8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       133\n",
      "           1       0.83      0.97      0.89        30\n",
      "           2       0.90      0.90      0.90        10\n",
      "           3       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.96       182\n",
      "   macro avg       0.90      0.90      0.90       182\n",
      "weighted avg       0.96      0.96      0.96       182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_nonull.label, results_nonull.predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36041d85",
   "metadata": {},
   "source": [
    "The other option is to fill null values with the most likely prediction (the default). As we can see, this doesn't work that well, since the most common prediction by definition has the most complete data, and therefore is rarely the answer we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f62690b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fillnull = results.fillna(results_nonull.label.value_counts().idxmax(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44f97159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.875\n",
      "chance is 0.670\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy is {accuracy_score(results_fillnull.label, results_fillnull.predictions):.3f}')\n",
    "print(f'chance is {sum(np.array(results_fillnull.label) == results_fillnull.label.value_counts().idxmax())/len(results_fillnull.label):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e3c32d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93       134\n",
      "           1       0.83      0.72      0.77        40\n",
      "           2       0.90      0.60      0.72        15\n",
      "           3       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.87      0.73      0.79       200\n",
      "weighted avg       0.87      0.88      0.87       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results_fillnull.label, results_fillnull.predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0c02e",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Let's expand the decision tree algorithm to the random forest algorithm.\n",
    "\n",
    "Basically, the RF algorithm extends the classic decision tree with two upgrades:\n",
    "\n",
    "1. generate samples. Rather than create one deceision tree from all of the training data, RF genrates samples from the training data to create \"weak\" learners. \n",
    "2. forest features. Similarly, each tree is trained off of a subset of features to a max depth.\n",
    "3. predictions are generated by taking the mode of the predictions from every graph produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5ac88dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomforest(dtree):\n",
    "    \"\"\"\n",
    "    A simple random forest algorithm, expanded from a decision tree algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # call super()\n",
    "        super().__init__()\n",
    "        self.dtree = dtree()\n",
    "\n",
    "        \n",
    "    def rf(self,data,classes,features,nTrees,nSamples,nFeatures,maxlevel=-1):\n",
    "        \"\"\"\n",
    "        Random forest loop.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            dataframe of values with features on columns and measurement intervals on rows\n",
    "            class target labels are not on this dataframe\n",
    "        classes : pd.Series\n",
    "            target class labels for the data\n",
    "        features : list\n",
    "            list of features to train the algorithm. All features must be rows in data\n",
    "        nTrees : int\n",
    "            number of random trees to generate\n",
    "        nSamples : int\n",
    "            number of samples to randomly select per each tree in the random forest\n",
    "        nFeatures : int\n",
    "            number of features to randomly select per each tree in the random forest\n",
    "        maxlevel : int\n",
    "            maximum depth of the decision tree\n",
    "            -1 leads to max depth\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tree_list : list(dict)\n",
    "            list of n graphs, where n=nTrees        \n",
    "        \"\"\"\n",
    "        tree_list = []\n",
    "\n",
    "        for i in range(nTrees):\n",
    "            print(i)\n",
    "            # Compute bootstrap samples\n",
    "            sample = data.sample(n=nSamples)\n",
    "            sampleTarget = classes.loc[sample.index]\n",
    "\n",
    "            tree_list.append(self.dtree.make_tree(sample,\n",
    "                                                  sampleTarget,\n",
    "                                                  featureNames,\n",
    "                                                  maxlevel=maxlevel,\n",
    "                                                  forest=nFeatures))\n",
    "    \n",
    "        return tree_list\n",
    "    \n",
    "    \n",
    "    def rfpredict(self, tree_list, data):\n",
    "        \"\"\"\n",
    "        predict class through majority voding of all trees generated by the random forest algorithm\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        tree_list : list(dict)\n",
    "            list of graphs producted by iterative generation of decision trees generated by rf\n",
    "        data : pd.DataFrame\n",
    "            df of values with features on columns and measures per row\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        decision : pd.Series\n",
    "            array of majority-vote predictions\n",
    "            may contain null values for edge cases\n",
    "        \"\"\"\n",
    "        # Majority voting\n",
    "        yhats = pd.DataFrame()\n",
    "        for t, tree in enumerate(tree_list):\n",
    "            yhats[f'tree_{t}'] = dt.predictAll(tree, data)\n",
    "\n",
    "        decision = yhats.mode(axis=1)\n",
    "        if decision.shape[1] > 1:\n",
    "            decision = decision[0] \n",
    "                \n",
    "        return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af44c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = randomforest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9eac98d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b48ddbfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "tree_list = rf.rf(train, train_classes, features=featureNames, nTrees=50, nSamples=len(train)//3, nFeatures=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a72aed",
   "metadata": {},
   "source": [
    "### Training classification\n",
    "Random forests are less deterministic (but still pretty close). That little bit of stocasticity means that training samples will not be perfectly fit. This is a very good thing -- overfitting is bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "343ab244",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = rf.rfpredict(tree_list, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7696c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1076\n",
      "           1       0.96      0.99      0.98       344\n",
      "           2       0.92      0.91      0.92        54\n",
      "           3       0.93      0.96      0.95        54\n",
      "\n",
      "    accuracy                           0.98      1528\n",
      "   macro avg       0.95      0.96      0.96      1528\n",
      "weighted avg       0.99      0.98      0.99      1528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_classes, train_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1c5dc",
   "metadata": {},
   "source": [
    "### Testing classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b65e80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = rf.rfpredict(tree_list, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9e347f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with enough iterations of random forests, we greatly reduce the possibility of null values\n",
    "test_preds.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3f4d859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       134\n",
      "           1       0.74      0.93      0.82        40\n",
      "           2       0.50      0.47      0.48        15\n",
      "           3       0.44      0.36      0.40        11\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.67      0.68      0.67       200\n",
      "weighted avg       0.88      0.88      0.87       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_classes, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "46468c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.875\n",
      "chance is 0.670\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy is {accuracy_score(test_classes, test_preds):.3f}')\n",
    "print(f'chance is {sum(test_classes == test_classes.mode()[0])/len(test_classes):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b0906",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Random forest algorithms are pretty powerful for being so conceptually simple. They still have many of the downfalls of linear classifiers, and become exponentially more complex with each new feature added. However, for simple classification they get the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b183ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lbdev",
   "language": "python",
   "name": "lbdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
